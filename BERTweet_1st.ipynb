{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Euna-Kim322/769_NLP_HLE/blob/main/BERTweet_1st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT2MuwMf0Ey3",
        "outputId": "d61a46e9-e7b0-4751-fadc-262c6a9249fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/drive/MyDrive/ColabNotebooks/hw3/setup.sh  # Make the script executable\n",
        "!./drive/MyDrive/ColabNotebooks/hw3/setup.sh  # Run the script"
      ],
      "metadata": {
        "id": "ribKlvON0v96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y build-essential\n",
        "!pip install tokenizers\n",
        "!pip install torch-optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzdQVGbk0t-8",
        "outputId": "8f27cf9e-0293-46c0-af38-cf7170ac80fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [589 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,185 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,455 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,012 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,389 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,278 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.5 kB]\n",
            "Fetched 10.7 MB in 9s (1,207 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.18,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub, tokenizers\n",
            "Successfully installed huggingface_hub-0.17.3 tokenizers-0.14.1\n",
            "Collecting torch-optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch-optimizer) (2.1.0+cu118)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch-optimizer)\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch-optimizer) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch-optimizer) (1.3.0)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip3 install emoji==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La7Br3dOC28L",
        "outputId": "e05374a8-4866-41c3-a9c5-3e636ad39541"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Collecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, transformers\n",
            "Successfully installed safetensors-0.4.0 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ColabNotebooks/hw3/classifier.py \\\n",
        "    --use_gpu \\\n",
        "    --option finetune \\\n",
        "    --lr 1e-5 \\\n",
        "    --seed 1234 \\\n",
        "    --train \"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-train.csv\" \\\n",
        "    --dev \"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev.csv\" \\\n",
        "    --test \"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test.csv\" \\\n",
        "    --dev_out \"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev-out.txt\" \\\n",
        "    --test_out \"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test-out.txt\" \\\n",
        "    --filepath \"/content/drive/MyDrive/ColabNotebooks/hw3/data/$mass_shooting-model.pt\" | tee /content/drive/MyDrive/ColabNotebooks/hw3/mess_shooting-train-log.txt\n",
        "#lr, finetune vs pretrain mode, seed?, model(Nadam, RAdam), from pretrained(bertweet-base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S13bVTii0nJ3",
        "outputId": "10cc5062-e1b0-4e11-89a8-a6f42c6b2af8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args: {'train': '/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-train.csv', 'dev': '/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev.csv', 'test': '/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test.csv', 'seed': 1234, 'epochs': 10, 'option': 'finetune', 'use_gpu': True, 'dev_out': '/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev-out.txt', 'test_out': '/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test-out.txt', 'filepath': '/content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt', 'batch_size': 8, 'hidden_dropout_prob': 0.3, 'lr': 1e-05}\n",
            "load 2000 data from /content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-train.csv\n",
            "load 500 data from /content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev.csv\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 0: train loss :: -3.491, train acc :: 0.782, dev acc :: 0.796\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 1: train loss :: -4.575, train acc :: 0.825, dev acc :: 0.840\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 2: train loss :: -5.255, train acc :: 0.841, dev acc :: 0.850\n",
            "epoch 3: train loss :: -5.914, train acc :: 0.840, dev acc :: 0.848\n",
            "epoch 4: train loss :: -6.589, train acc :: 0.836, dev acc :: 0.840\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 5: train loss :: -7.331, train acc :: 0.863, dev acc :: 0.874\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 6: train loss :: -8.083, train acc :: 0.942, dev acc :: 0.900\n",
            "save the model to /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "epoch 7: train loss :: -8.864, train acc :: 0.944, dev acc :: 0.906\n",
            "epoch 8: train loss :: -9.633, train acc :: 0.949, dev acc :: 0.886\n",
            "epoch 9: train loss :: -10.447, train acc :: 0.961, dev acc :: 0.904\n",
            "load model from /content/drive/MyDrive/ColabNotebooks/hw3/data/-model.pt\n",
            "load 500 data from /content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-dev.csv\n",
            "load 1500 data from /content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test.csv\n",
            "dev acc :: 0.906\n",
            "test acc :: 0.906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Read the file and split by lines\n",
        "with open(\"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test-out.txt\", 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Parse the context, true label, and predicted label from each line\n",
        "contexts, true_labels, predicted_labels = [], [], []\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.strip().split(\" ||| \")\n",
        "    if len(parts) == 3:\n",
        "        contexts.append(parts[0])\n",
        "        true_labels.append(int(parts[1]))\n",
        "        predicted_labels.append(int(parts[2]))\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "df = pd.DataFrame({\n",
        "    'Context': contexts,\n",
        "    'True_Label': true_labels,\n",
        "    'Predicted_Label': predicted_labels\n",
        "})\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Basic Analysis\n",
        "print(\"\\nTotal number of records:\", len(df))\n",
        "print(\"\\nNumber of correctly predicted labels:\", sum(df['True_Label'] == df['Predicted_Label']))\n",
        "\n",
        "# For a more detailed error analysis\n",
        "errors = df[df['True_Label'] != df['Predicted_Label']]\n",
        "print(\"\\nNumber of incorrect predictions:\", len(errors))\n",
        "\n",
        "# Display first 10 incorrect predictions for inspection\n",
        "print(\"\\nSample Incorrect Predictions:\")\n",
        "print(errors.head(10))\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "print(\"\\nF1 Score:\", f1)\n",
        "\n",
        "# Classification Report for more detailed metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR3ASetF2ANh",
        "outputId": "261b55cf-a80d-4484-8e10-581ad951630f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Context  True_Label  \\\n",
            "0  rt @ddlovato: really sad to hear that there wa...           3   \n",
            "1  @coolneguy border patrol agent accused in fata...           0   \n",
            "2  rt @goldwatergal: repeat after me: gun control...           0   \n",
            "3  east palo alto: one killed, four injured in sh...           0   \n",
            "4  rt @tweetslmao: so if guns kill people, i gues...           0   \n",
            "\n",
            "   Predicted_Label  \n",
            "0                3  \n",
            "1                0  \n",
            "2                0  \n",
            "3                0  \n",
            "4                0  \n",
            "\n",
            "Total number of records: 1500\n",
            "\n",
            "Number of correctly predicted labels: 1359\n",
            "\n",
            "Number of incorrect predictions: 141\n",
            "\n",
            "Sample Incorrect Predictions:\n",
            "                                              Context  True_Label  \\\n",
            "14  rt @willspencer: i can't wait to be lectured a...           2   \n",
            "33  rt @seamuskrat: i gave @molonlabenj +k about g...           2   \n",
            "54  rt @theblaze: 163 dems sign letter to john boe...           0   \n",
            "55  illinoiscarry on possible bill this week. #il ...           2   \n",
            "61  rt @billmaher: sorry but prayers and giving yo...           0   \n",
            "68  rt @jennyjohnsonhi5: the shootings in connecti...           3   \n",
            "80  rt @david_schulze: members of @nj2as support @...           0   \n",
            "82  rt @askjimmycarter: it's not guns,box cutters ...           1   \n",
            "84  rt @nranews: statement from the national rifle...           0   \n",
            "89  rt @czarzellem: marine pulls gun on rampaging ...           2   \n",
            "\n",
            "    Predicted_Label  \n",
            "14                0  \n",
            "33                0  \n",
            "54                1  \n",
            "55                0  \n",
            "61                3  \n",
            "68                0  \n",
            "80                2  \n",
            "82                0  \n",
            "84                1  \n",
            "89                0  \n",
            "\n",
            "F1 Score: 0.8997675294072354\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95      1237\n",
            "           1       0.68      0.43      0.53        99\n",
            "           2       0.82      0.60      0.69        75\n",
            "           3       0.80      0.92      0.85        89\n",
            "\n",
            "    accuracy                           0.91      1500\n",
            "   macro avg       0.81      0.73      0.76      1500\n",
            "weighted avg       0.90      0.91      0.90      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Read the file and split by lines\n",
        "with open(\"/content/drive/MyDrive/ColabNotebooks/hw3/data/mass_shooting-test-out.txt\", 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Parse the context, true label, and predicted label from each line\n",
        "contexts, true_labels, predicted_labels = [], [], []\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.strip().split(\" ||| \")\n",
        "    if len(parts) == 3:\n",
        "        contexts.append(parts[0])\n",
        "        true_labels.append(int(parts[1]))\n",
        "        predicted_labels.append(int(parts[2]))\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "df = pd.DataFrame({\n",
        "    'Context': contexts,\n",
        "    'True_Label': true_labels,\n",
        "    'Predicted_Label': predicted_labels\n",
        "})\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Basic Analysis\n",
        "print(\"\\nTotal number of records:\", len(df))\n",
        "print(\"\\nNumber of correctly predicted labels:\", sum(df['True_Label'] == df['Predicted_Label']))\n",
        "\n",
        "# For a more detailed error analysis\n",
        "errors = df[df['True_Label'] != df['Predicted_Label']]\n",
        "print(\"\\nNumber of incorrect predictions:\", len(errors))\n",
        "\n",
        "# Display first few incorrect predictions for inspection\n",
        "print(\"\\nSample Incorrect Predictions:\")\n",
        "print(errors.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZn2GuEv2WOT",
        "outputId": "f31ed913-a64a-49cb-b3fb-7e29f9d4b7c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Context  True_Label  \\\n",
            "0  rt @ddlovato: really sad to hear that there wa...           3   \n",
            "1  @coolneguy border patrol agent accused in fata...           0   \n",
            "2  rt @goldwatergal: repeat after me: gun control...           0   \n",
            "3  east palo alto: one killed, four injured in sh...           0   \n",
            "4  rt @tweetslmao: so if guns kill people, i gues...           0   \n",
            "\n",
            "   Predicted_Label  \n",
            "0                3  \n",
            "1                0  \n",
            "2                0  \n",
            "3                0  \n",
            "4                0  \n",
            "\n",
            "Total number of records: 1500\n",
            "\n",
            "Number of correctly predicted labels: 1359\n",
            "\n",
            "Number of incorrect predictions: 141\n",
            "\n",
            "Sample Incorrect Predictions:\n",
            "                                              Context  True_Label  \\\n",
            "14  rt @willspencer: i can't wait to be lectured a...           2   \n",
            "33  rt @seamuskrat: i gave @molonlabenj +k about g...           2   \n",
            "54  rt @theblaze: 163 dems sign letter to john boe...           0   \n",
            "55  illinoiscarry on possible bill this week. #il ...           2   \n",
            "61  rt @billmaher: sorry but prayers and giving yo...           0   \n",
            "\n",
            "    Predicted_Label  \n",
            "14                0  \n",
            "33                0  \n",
            "54                1  \n",
            "55                0  \n",
            "61                3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjVQrkQ4Oe7s",
        "outputId": "0d7457d4-5b0f-46d9-ad43-244747a884da"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=2.0 (from bertviz)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.1)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.28.75-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.6.3)\n",
            "Collecting sentencepiece (from bertviz)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.14.1)\n",
            "Collecting safetensors>=0.3.1 (from transformers>=2.0->bertviz)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.32.0,>=1.31.75 (from boto3->bertviz)\n",
            "  Downloading botocore-1.31.75-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.75->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.75->boto3->bertviz) (1.16.0)\n",
            "Installing collected packages: sentencepiece, safetensors, jmespath, botocore, s3transfer, transformers, boto3, bertviz\n",
            "Successfully installed bertviz-1.4.0 boto3-1.28.75 botocore-1.31.75 jmespath-1.0.1 s3transfer-0.7.0 safetensors-0.4.0 sentencepiece-0.1.99 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, utils\n",
        "from bertviz import model_view\n",
        "\n",
        "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
        "\n",
        "model_name = \"microsoft/xtremedistil-l12-h384-uncased\"  # Find popular HuggingFace models here: https://huggingface.co/models\n",
        "input_text = \"The cat sat on the mat\"\n",
        "model = AutoModel.from_pretrained(model_name, output_attentions=True)  # Configure model to return attention values\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
        "outputs = model(inputs)  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
        "model_view(attention, tokens)  # Display model view"
      ],
      "metadata": {
        "id": "vviL2126SoUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PXpghdoIOet2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the Most of your Colab Subscription",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}